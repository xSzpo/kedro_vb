# Here you can define all your data sets by using simple YAML syntax.
#
# Documentation for this file format can be found in "The Data Catalog"
# Link: https://kedro.readthedocs.io/en/stable/05_data/01_data_catalog.html

customers:
  type: pandas.CSVDataSet
  filepath: data/01_raw/customers.csv
  load_args: {
    "names":['customerID','sex','age','residentialAddress','postalAddress','income'],
    }
  layer: raw

transactions:
  type: pandas.CSVDataSet
  filepath: data/01_raw/transactions.csv
  load_args: {
    "names":['transactionID','shopID','customerID','price','paymentStatus1','paymentStatus2','paymentStatus3','paymentStatus4'],    }
  layer: raw

master_table:
  type: pandas.ParquetDataSet
  filepath: data/03_primary/master_table.parquet
  layer: primary

df_oot:
  type: pandas.ParquetDataSet
  filepath: data/05_model_input/df_oot.parquet
  layer: primary

df_train:
  type: pandas.ParquetDataSet
  filepath: data/05_model_input/df_train.parquet
  layer: primary

df_test:
  type: pandas.ParquetDataSet
  filepath: data/05_model_input/df_test.parquet
  layer: primary

df_valid:
  type: pandas.ParquetDataSet
  filepath: data/05_model_input/df_valid.parquet
  layer: primary

model_lgb_params:
  type: kedro_mlflow.io.artifacts.MlflowArtifactDataSet
  data_set:
    type: json.JSONDataSet
    filepath: data/06_models/model_lgb_params.json
  layer: 06_models